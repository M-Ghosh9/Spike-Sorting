# data_loader.py

import os
import numpy as np
import torch
from concurrent.futures import ThreadPoolExecutor
from sklearn.preprocessing import StandardScaler

def read_file_with_label(file_path, label):
    file_data = []
    with open(file_path, 'r') as f:
        file_data = [list(map(float, line.split())) for line in f if line.strip()]
    return file_data, label

def load_data_with_labels_optimized(directory):
    all_signals = []
    all_labels = []
    max_length = 0
    file_paths = []

    current_label = 0
    for root, dirs, _ in os.walk(directory):
        for dir_name in dirs:
            dir_path = os.path.join(root, dir_name)
            for subdir_root, subdirs, files in os.walk(dir_path):
                for file in sorted(files):
                    if file.endswith('.txt'):
                        file_path = os.path.join(subdir_root, file)
                        label = current_label  # Assigning unique label
                        file_paths.append((file_path, label))
                        current_label += 1  # Increment label for next file

    with ThreadPoolExecutor() as executor:
        results = list(executor.map(lambda fp: read_file_with_label(fp[0], fp[1]), file_paths))

    for file_data, label in results:
        if file_data:
            all_signals.extend(file_data)
            all_labels.extend([label] * len(file_data))
            max_length = max(max_length, max(len(signal) for signal in file_data))

    padded_signals = [signal + [0] * (max_length - len(signal)) for signal in all_signals]
    return np.array(padded_signals), np.array(all_labels)

def preprocess_data(signals):
    scaler = StandardScaler()
    signals_normalized = scaler.fit_transform(signals)
    signals_reshaped = torch.tensor(signals_normalized, dtype=torch.float32).unsqueeze(1)
    return signals_reshaped, scaler

if __name__ == "__main__":
    DATA_DIR = '/home/Guest/Downloads/Transfer Learning/TrainingData'
    signals, labels = load_data_with_labels_optimized(DATA_DIR)
    signals_reshaped, scaler = preprocess_data(signals)
    torch.save((signals_reshaped, labels), 'signals.pt')
    print(f"Data loaded and preprocessed. Shape: {signals_reshaped.shape}")
    print(f"Labels loaded. Shape: {labels.shape}")
    print(f"Unique labels: {np.unique(labels)[:10]}")
    print(f"Number of unique labels: {len(np.unique(labels))}")

# data_to_images.py

import os
import matplotlib.pyplot as plt
import torch
import numpy as np
from concurrent.futures import ThreadPoolExecutor

def save_spike_images(signals, labels, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    unique_labels = np.unique(labels)

    with ThreadPoolExecutor() as executor:
        for label in unique_labels:
            label_str = str(label)
            label_dir = os.path.join(output_dir, label_str)
            os.makedirs(label_dir, exist_ok=True)

            indices = np.where(labels == label)[0]
            list(executor.map(lambda i: save_image(signals[i], label_dir, i), indices))

def save_image(signal, label_dir, index):
    try:
        fig, ax = plt.subplots(figsize=(1, 1), dpi=100)
        ax.plot(signal)
        ax.axis('off')

        img_path = os.path.join(label_dir, f"{index}.png")
        plt.savefig(img_path, bbox_inches='tight', pad_inches=0)
        plt.close(fig)
    except Exception as e:
        print(f"Error saving image {index} in {label_dir}: {e}")

if __name__ == "__main__":
    signals, labels = torch.load('signals.pt')
    signals = signals.squeeze().cpu().numpy()

    IMG_OUTPUT_DIR = 'spike_images'

    print("Converting spikes to images...")
    save_spike_images(signals, labels, IMG_OUTPUT_DIR)
    print(f"Spike images saved to {IMG_OUTPUT_DIR}")

#greyscale.py

import os
from PIL import Image
import torch
import torchvision.transforms as transforms

def load_and_preprocess_images(image_dir, img_size=(28, 28)):
    transform = transforms.Compose([
        transforms.Grayscale(),
        transforms.Resize(img_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    images = []
    image_labels = []

    for label_dir in os.listdir(image_dir):
        label_path = os.path.join(image_dir, label_dir)
        if os.path.isdir(label_path):
            for img_file in os.listdir(label_path):
                img_path = os.path.join(label_path, img_file)
                try:
                    image = Image.open(img_path).convert('L')
                    image = transform(image)
                    images.append(image)
                    image_labels.append(label_dir)
                except Exception as e:
                    print(f"Error loading image {img_path}: {e}")

    return torch.stack(images), image_labels

if __name__ == "__main__":
    IMG_OUTPUT_DIR = 'spike_images'
    print("Loading and preprocessing images...")
    images, image_labels = load_and_preprocess_images(IMG_OUTPUT_DIR)
    torch.save((images, image_labels), 'images.pt')
    print(f"Images loaded and preprocessed. Shape: {images.shape}")
    print(f"Image labels loaded. Shape: {len(image_labels)}")

#model.py

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models
from torch.utils.data import DataLoader, TensorDataset, random_split
import numpy as np
from sklearn.preprocessing import LabelEncoder
import os

class CustomResNet(nn.Module):
    def __init__(self, num_classes):
        super(CustomResNet, self).__init__()
        self.resnet = models.resnet18(weights='DEFAULT')
        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)

    def forward(self, x):
        return self.resnet(x)

def evaluate_model(model, dataloader, criterion, device):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            running_loss += loss.item()

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

    loss = running_loss / len(dataloader)
    accuracy = 100. * correct / total
    return loss, accuracy

def save_checkpoint(state, filename='checkpoint.pth'):
    torch.save(state, filename)
    print(f"Checkpoint saved as '{filename}'")

def load_checkpoint(filename='checkpoint.pth', model=None, optimizer=None):
    if os.path.isfile(filename):
        print(f"Loading checkpoint '{filename}'")
        checkpoint = torch.load(filename)
        if model is not None:
            model.load_state_dict(checkpoint['model_state_dict'])
        if optimizer is not None:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        epoch = checkpoint['epoch']
        best_val_accuracy = checkpoint['best_val_accuracy']
        return epoch, best_val_accuracy
    else:
        print(f"No checkpoint found at '{filename}'")
        return 0, 0

def predict(model, dataloader, device):
    model.eval()
    all_predictions = []
    all_probabilities = []

    with torch.no_grad():
        for inputs, _ in dataloader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            _, predicted = outputs.max(1)
            all_predictions.extend(predicted.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())

    return np.array(all_predictions), np.array(all_probabilities)

if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # Load preprocessed images and labels
    images, image_labels = torch.load('images.pt')
    images = images.to(device)
    
    # Encode labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(image_labels)
    encoded_labels = torch.tensor(encoded_labels, dtype=torch.long).to(device)

    # Create dataset
    dataset = TensorDataset(images, encoded_labels)

    # Move encoded_labels to CPU before converting to NumPy array
    encoded_labels_cpu = encoded_labels.cpu().numpy()

    # Get the number of unique classes
    num_classes = len(np.unique(encoded_labels_cpu))
    
    # Split dataset into training and validation sets (80-20)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)

    # Initialize model, criterion, and optimizer
    model = CustomResNet(num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.0001)

    # Load checkpoint if available
    start_epoch, best_val_accuracy = load_checkpoint('checkpoint.pth', model, optimizer)
    
    # Training loop
    num_epochs = 100
    for epoch in range(start_epoch, num_epochs):
        model.train()
        running_loss = 0.0
        correct = 0
        total = 0
        for inputs, labels in train_dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        train_loss = running_loss / len(train_dataloader)
        train_accuracy = 100. * correct / total

        val_loss, val_accuracy = evaluate_model(model, val_dataloader, criterion, device)

        print(f"Epoch {epoch+1}/{num_epochs}, "
              f"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, "
              f"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%")

        # Save checkpoint 
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            save_checkpoint({
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_accuracy': best_val_accuracy
            })

    # Final save
    torch.save(model.state_dict(), 'spike_classifier.pth')
    print("Final model saved as 'spike_classifier.pth'")

    # Predict and convert images to spikes
    model.load_state_dict(torch.load('spike_classifier.pth'))
    model.to(device)
    
    # Create DataLoader for predictions (same images used for training here)
    test_dataloader = DataLoader(dataset, batch_size=32, shuffle=False)
    
    # Predict on the entire dataset
    predictions, probabilities = predict(model, test_dataloader, device)

    # Convert predictions to class labels
    predicted_labels = label_encoder.inverse_transform(predictions)
    
    # Save predictions to file
    np.save('predicted_labels.npy', predicted_labels)
    np.save('probabilities.npy', probabilities)
    
    print("Predictions and probabilities saved.")

#image_to_data.py

import os
from PIL import Image
import numpy as np
import torchvision.transforms as transforms

def convert_images_to_spikes(image_dir, img_size=(28, 28)):
    transform = transforms.Compose([
        transforms.Grayscale(),
        transforms.Resize(img_size),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    spikes = []
    spike_labels = []

    for label_dir in os.listdir(image_dir):
        label_path = os.path.join(image_dir, label_dir)
        if os.path.isdir(label_path):
            for img_file in os.listdir(label_path):
                img_path = os.path.join(label_path, img_file)
                try:
                    image = Image.open(img_path).convert('L')
                    image = transform(image)
                    spike = image.numpy().flatten()
                    spikes.append(spike)
                    spike_labels.append(int(label_dir))  # Convert label_dir to integer if necessary
                except Exception as e:
                    print(f"Error processing image {img_path}: {e}")

    return np.array(spikes), np.array(spike_labels)

if __name__ == "__main__":
    IMG_OUTPUT_DIR = 'spike_images'  # Directory containing images

    # Convert images back to spikes
    converted_spikes, converted_labels = convert_images_to_spikes(IMG_OUTPUT_DIR)
    
    print(f"Converted spikes shape: {converted_spikes.shape}")
    print(f"Converted labels shape: {len(converted_labels)}")

    # Save converted spikes and labels
    np.save('converted_spikes.npy', converted_spikes)
    np.save('converted_labels.npy', converted_labels)
    print("Converted spikes and labels saved to 'converted_spikes.npy' and 'converted_labels.npy'")
#performance.py

import matplotlib.pyplot as plt
import numpy as np
import torch
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

def plot_performance_metrics(true_labels, predicted_labels, label_encoder):
    cm = confusion_matrix(true_labels, predicted_labels)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title("Confusion Matrix")
    plt.show()

    # Plot some example spikes
    num_examples = 10
    unique_labels = np.unique(true_labels)
    for label in unique_labels:
        indices = np.where(true_labels == label)[0][:num_examples]
        plt.figure(figsize=(10, 5))
        for i in indices:
            plt.plot(converted_spikes[i], alpha=0.5)
        plt.title(f'Neuron {label_encoder.inverse_transform([label])[0]} - Example Spikes')
        plt.xlabel('Time')
        plt.ylabel('Amplitude')
        plt.show()

if __name__ == "__main__":
    # Load model and data
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CustomResNet(len(label_encoder.classes_)).to(device)
    model.load_state_dict(torch.load('spike_classifier.pth'))
    model.eval()

    # Predict on the entire dataset
    all_predictions = []
    with torch.no_grad():
        for inputs in dataloader:
            inputs = inputs[0].to(device)
            outputs = model(inputs)
            _, predicted = outputs.max(1)
            all_predictions.extend(predicted.cpu().numpy())

    all_predictions = np.array(all_predictions)

    # Plot performance metrics
    plot_performance_metrics(encoded_labels, all_predictions, label_encoder)

